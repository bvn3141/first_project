{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5fbb8f",
   "metadata": {},
   "source": [
    "# 05 - Export Dashboard Data\n",
    "\n",
    "Generates pre-processed JSON files for the React dashboard. Replaces mock data with real Transfermarkt results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DB_PATH = Path('..') / 'data' / 'processed' / 'football.db'\n",
    "OUT_DIR = Path('..') / 'dashboard' / 'public' / 'data'\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "LEAGUE_NAMES = {'GB1': 'Premier League', 'ES1': 'La Liga', 'IT1': 'Serie A', 'L1': 'Bundesliga', 'FR1': 'Ligue 1'}\n",
    "\n",
    "def save(name, data):\n",
    "    path = OUT_DIR / name\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=2, default=str)\n",
    "    n = len(data) if isinstance(data, list) else sum(len(v) if isinstance(v, list) else 1 for v in data.values())\n",
    "    print(f\"  {name} -> {path.stat().st_size/1024:.1f} KB ({n} records)\")\n",
    "\n",
    "print(f\"Output: {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00aad35",
   "metadata": {},
   "source": [
    "## 1. market_overview.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_sql('''\n",
    "    WITH yearly AS (\n",
    "        SELECT\n",
    "            CAST(strftime('%Y', date) AS INTEGER) as year,\n",
    "            player_club_domestic_competition_id as league_id,\n",
    "            SUM(market_value_in_eur) as total_market_value,\n",
    "            COUNT(DISTINCT player_id) as player_count,\n",
    "            AVG(market_value_in_eur) as avg_player_value\n",
    "        FROM player_valuations\n",
    "        WHERE player_club_domestic_competition_id IN ('GB1','ES1','IT1','L1','FR1')\n",
    "          AND market_value_in_eur > 0\n",
    "          AND strftime('%m', date) = '01'\n",
    "        GROUP BY year, league_id\n",
    "    )\n",
    "    SELECT year, league_id, total_market_value, player_count, avg_player_value,\n",
    "        ROUND(\n",
    "            (total_market_value - LAG(total_market_value) OVER (PARTITION BY league_id ORDER BY year))\n",
    "            * 100.0\n",
    "            / NULLIF(LAG(total_market_value) OVER (PARTITION BY league_id ORDER BY year), 0),\n",
    "        1) as yoy_growth_pct\n",
    "    FROM yearly\n",
    "    WHERE year BETWEEN 2012 AND 2025\n",
    "    ORDER BY year, league_id\n",
    "''', conn)\n",
    "df['league_name'] = df['league_id'].map(LEAGUE_NAMES)\n",
    "df['total_market_value'] = df['total_market_value'].round(0)\n",
    "df['avg_player_value'] = df['avg_player_value'].round(0)\n",
    "df['yoy_growth_pct'] = df['yoy_growth_pct'].where(df['yoy_growth_pct'].notna(), other=None)\n",
    "save('market_overview.json', df.to_dict('records'))\n",
    "display(df[df['league_id']=='GB1'][['year','total_market_value','player_count','yoy_growth_pct']].tail(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225fbad",
   "metadata": {},
   "source": [
    "## 2. league_comparison.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6146a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_sql('''\n",
    "    WITH latest_year AS (\n",
    "        SELECT MAX(CAST(strftime('%Y', date) AS INTEGER)) - 1 as yr\n",
    "        FROM player_valuations\n",
    "        WHERE player_club_domestic_competition_id IN ('GB1','ES1','IT1','L1','FR1')\n",
    "    ),\n",
    "    league_totals AS (\n",
    "        SELECT pv.player_club_domestic_competition_id as league_id,\n",
    "            SUM(pv.market_value_in_eur) as total_value,\n",
    "            AVG(pv.market_value_in_eur) as avg_value,\n",
    "            COUNT(DISTINCT pv.player_id) as player_count\n",
    "        FROM player_valuations pv, latest_year ly\n",
    "        WHERE pv.player_club_domestic_competition_id IN ('GB1','ES1','IT1','L1','FR1')\n",
    "          AND pv.market_value_in_eur > 0\n",
    "          AND CAST(strftime('%Y', pv.date) AS INTEGER) = ly.yr\n",
    "        GROUP BY pv.player_club_domestic_competition_id\n",
    "    ),\n",
    "    club_vals AS (\n",
    "        SELECT c.domestic_competition_id as league_id, c.name as club_name,\n",
    "            c.total_market_value,\n",
    "            ROW_NUMBER() OVER (PARTITION BY c.domestic_competition_id ORDER BY c.total_market_value DESC) as rn\n",
    "        FROM clubs c\n",
    "        WHERE c.domestic_competition_id IN ('GB1','ES1','IT1','L1','FR1')\n",
    "          AND c.total_market_value > 0\n",
    "    )\n",
    "    SELECT lt.league_id, lt.total_value, lt.avg_value, lt.player_count,\n",
    "        cv.club_name as top_club, cv.total_market_value as top_club_value\n",
    "    FROM league_totals lt\n",
    "    LEFT JOIN club_vals cv ON lt.league_id = cv.league_id AND cv.rn = 1\n",
    "    ORDER BY lt.total_value DESC\n",
    "''', conn)\n",
    "df['league'] = df['league_id'].map(LEAGUE_NAMES)\n",
    "df[['total_value','avg_value','top_club_value']] = df[['total_value','avg_value','top_club_value']].round(0)\n",
    "save('league_comparison.json', df.to_dict('records'))\n",
    "display(df[['league','player_count','top_club']].round(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ff7fa",
   "metadata": {},
   "source": [
    "## 3. top_transfers.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963099a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_sql('''\n",
    "    SELECT player_name, from_club_name as from_club, to_club_name as to_club,\n",
    "        ROUND(transfer_fee) as fee, transfer_season as season, transfer_date\n",
    "    FROM transfers\n",
    "    WHERE transfer_fee > 0\n",
    "    ORDER BY transfer_fee DESC LIMIT 15\n",
    "''', conn)\n",
    "save('top_transfers.json', df.to_dict('records'))\n",
    "display(df[['player_name','from_club','to_club','fee']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c660a37",
   "metadata": {},
   "source": [
    "## 4. age_curves.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54405e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_sql('''\n",
    "    SELECT\n",
    "        CAST((julianday(pv.date) - julianday(p.date_of_birth)) / 365.25 AS INTEGER) as age,\n",
    "        p.position, pv.market_value_in_eur / 1e6 as value_m\n",
    "    FROM player_valuations pv\n",
    "    JOIN players p ON pv.player_id = p.player_id\n",
    "    WHERE p.position IN ('Attack', 'Midfield', 'Defender', 'Goalkeeper')\n",
    "      AND p.date_of_birth IS NOT NULL\n",
    "      AND pv.market_value_in_eur > 0\n",
    "      AND pv.date >= '2015-01-01'\n",
    "''', conn)\n",
    "df = df[(df['age'] >= 17) & (df['age'] <= 38)]\n",
    "pivot = df.groupby(['age','position'])['value_m'].median().unstack('position').reset_index()\n",
    "for col in ['Attack','Midfield','Defender','Goalkeeper']:\n",
    "    if col in pivot.columns:\n",
    "        pivot[col] = pivot[col].round(3)\n",
    "save('age_curves.json', pivot.to_dict('records'))\n",
    "display(pivot.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556cd86",
   "metadata": {},
   "source": [
    "## 5. risk_metrics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e72822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_vol = pd.read_sql('''\n",
    "    WITH monthly AS (\n",
    "        SELECT player_club_domestic_competition_id as league_id,\n",
    "            strftime('%Y', date) as season, strftime('%m', date) as month,\n",
    "            AVG(market_value_in_eur) as avg_val\n",
    "        FROM player_valuations\n",
    "        WHERE player_club_domestic_competition_id IN ('GB1','ES1','IT1','L1','FR1')\n",
    "          AND market_value_in_eur > 0 AND date >= '2015-01-01'\n",
    "        GROUP BY league_id, season, month\n",
    "    ),\n",
    "    returns AS (\n",
    "        SELECT league_id, season,\n",
    "            (avg_val - LAG(avg_val) OVER (PARTITION BY league_id ORDER BY season, month))\n",
    "            * 100.0 / NULLIF(LAG(avg_val) OVER (PARTITION BY league_id ORDER BY season, month), 0)\n",
    "            as monthly_ret\n",
    "        FROM monthly\n",
    "    )\n",
    "    SELECT league_id, season,\n",
    "        ROUND(SQRT(\n",
    "            (SUM(monthly_ret*monthly_ret)/COUNT(*)) - (AVG(monthly_ret)*AVG(monthly_ret))\n",
    "        ), 2) as volatility\n",
    "    FROM returns\n",
    "    WHERE monthly_ret IS NOT NULL\n",
    "    GROUP BY league_id, season HAVING COUNT(*) >= 6\n",
    "    ORDER BY season, league_id\n",
    "''', conn)\n",
    "df_vol['league'] = df_vol['league_id'].map(LEAGUE_NAMES)\n",
    "df_vol = df_vol[['league','season','volatility']].dropna()\n",
    "\n",
    "df_dd = pd.read_sql('''\n",
    "    WITH player_peak AS (\n",
    "        SELECT pv.player_id, p.position, pv.market_value_in_eur,\n",
    "            MAX(pv.market_value_in_eur) OVER (\n",
    "                PARTITION BY pv.player_id ORDER BY pv.date\n",
    "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "            ) as running_max\n",
    "        FROM player_valuations pv\n",
    "        JOIN players p ON pv.player_id = p.player_id\n",
    "        WHERE p.position IN ('Attack', 'Midfield', 'Defender', 'Goalkeeper')\n",
    "          AND pv.market_value_in_eur > 0\n",
    "    ),\n",
    "    drawdown AS (\n",
    "        SELECT player_id, position,\n",
    "            ROUND((market_value_in_eur - running_max) * 100.0 / running_max, 2) as drawdown_pct\n",
    "        FROM player_peak WHERE running_max > 0\n",
    "    ),\n",
    "    player_max_dd AS (\n",
    "        SELECT player_id, position, MIN(drawdown_pct) as max_drawdown\n",
    "        FROM drawdown GROUP BY player_id, position\n",
    "    )\n",
    "    SELECT position,\n",
    "        ROUND(AVG(max_drawdown), 1) as avg_max_drawdown,\n",
    "        ROUND(MIN(max_drawdown), 1) as worst_drawdown,\n",
    "        COUNT(*) as player_count\n",
    "    FROM player_max_dd GROUP BY position ORDER BY avg_max_drawdown\n",
    "''', conn)\n",
    "\n",
    "df_dep = pd.read_sql('''\n",
    "    WITH age_brackets AS (\n",
    "        SELECT p.position,\n",
    "            CASE\n",
    "                WHEN CAST((julianday(pv.date) - julianday(p.date_of_birth)) / 365.25 AS INT) < 21 THEN 'U21'\n",
    "                WHEN CAST((julianday(pv.date) - julianday(p.date_of_birth)) / 365.25 AS INT) < 25 THEN '21-24'\n",
    "                WHEN CAST((julianday(pv.date) - julianday(p.date_of_birth)) / 365.25 AS INT) < 28 THEN '25-27'\n",
    "                WHEN CAST((julianday(pv.date) - julianday(p.date_of_birth)) / 365.25 AS INT) < 31 THEN '28-30'\n",
    "                ELSE '31+'\n",
    "            END as age_bracket,\n",
    "            (pv.market_value_in_eur - LAG(pv.market_value_in_eur) OVER (PARTITION BY pv.player_id ORDER BY pv.date))\n",
    "            * 100.0 / NULLIF(LAG(pv.market_value_in_eur) OVER (PARTITION BY pv.player_id ORDER BY pv.date), 0)\n",
    "            as change_pct\n",
    "        FROM player_valuations pv\n",
    "        JOIN players p ON pv.player_id = p.player_id\n",
    "        WHERE p.position IN ('Attack', 'Midfield', 'Defender', 'Goalkeeper')\n",
    "          AND p.date_of_birth IS NOT NULL AND pv.market_value_in_eur > 0\n",
    "    )\n",
    "    SELECT position, age_bracket,\n",
    "        ROUND(AVG(change_pct), 2) as avg_change_pct,\n",
    "        ROUND(AVG(CASE WHEN change_pct < 0 THEN change_pct ELSE NULL END), 2) as depreciation_rate\n",
    "    FROM age_brackets\n",
    "    WHERE change_pct IS NOT NULL AND ABS(change_pct) < 200\n",
    "    GROUP BY position, age_bracket ORDER BY position, age_bracket\n",
    "''', conn)\n",
    "\n",
    "df_sharpe = pd.read_sql('''\n",
    "    WITH monthly_vals AS (\n",
    "        SELECT player_club_domestic_competition_id as league_id,\n",
    "            strftime('%Y-%m', date) as month, AVG(market_value_in_eur) as avg_val\n",
    "        FROM player_valuations\n",
    "        WHERE player_club_domestic_competition_id IN ('GB1','ES1','IT1','L1','FR1')\n",
    "          AND market_value_in_eur > 0 AND date >= '2015-01-01'\n",
    "        GROUP BY league_id, month\n",
    "    ),\n",
    "    monthly_rets AS (\n",
    "        SELECT league_id, month,\n",
    "            (avg_val - LAG(avg_val) OVER (PARTITION BY league_id ORDER BY month))\n",
    "            * 100.0 / NULLIF(LAG(avg_val) OVER (PARTITION BY league_id ORDER BY month), 0)\n",
    "            as ret\n",
    "        FROM monthly_vals\n",
    "    )\n",
    "    SELECT league_id,\n",
    "        ROUND(AVG(ret) * 12, 2) as avg_return,\n",
    "        ROUND(SQRT((SUM(ret*ret)/COUNT(*)) - (AVG(ret)*AVG(ret))) * SQRT(12), 2) as volatility,\n",
    "        ROUND(AVG(ret) / NULLIF(SQRT((SUM(ret*ret)/COUNT(*)) - (AVG(ret)*AVG(ret))), 0), 3) as sharpe_ratio\n",
    "    FROM monthly_rets\n",
    "    WHERE ret IS NOT NULL GROUP BY league_id ORDER BY sharpe_ratio DESC\n",
    "''', conn)\n",
    "df_sharpe['league'] = df_sharpe['league_id'].map(LEAGUE_NAMES)\n",
    "\n",
    "risk = {\n",
    "    'volatility_heatmap': df_vol.to_dict('records'),\n",
    "    'drawdown_by_position': df_dd.to_dict('records'),\n",
    "    'depreciation_rates': df_dep.to_dict('records'),\n",
    "    'sharpe_ratios': df_sharpe[['league','sharpe_ratio','avg_return','volatility']].to_dict('records'),\n",
    "}\n",
    "save('risk_metrics.json', risk)\n",
    "print(\"\\nDrawdown:\")\n",
    "display(df_dd)\n",
    "print(\"\\nSharpe:\")\n",
    "display(df_sharpe[['league','sharpe_ratio','avg_return','volatility']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b23c8",
   "metadata": {},
   "outputs": [],
   "source": "# Don't close yet -- more exports below"
  },
  {
   "cell_type": "markdown",
   "id": "3kl2dcbxze9",
   "source": "## 6. transfer_analytics.json\n\nROI distribution, club net spend, and fee-vs-value-change scatter. Uses a correlated subquery to find market value 1 year after each transfer.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "n38l07s2gmm",
   "source": "# Base query: transfers with market value at transfer time and ~1 year later\n# Correlated subquery is slow (~5 min) so we do it once and reuse\n# Note: SQLite bug limits outer-column references per subquery, so we use\n# a simpler approach: first valuation after +10 months (ORDER BY date ASC LIMIT 1)\nprint(\"Running correlated subquery (this takes a few minutes)...\")\ndf_transfers = pd.read_sql('''\n    SELECT\n        t.player_name,\n        t.transfer_fee,\n        t.transfer_date,\n        t.to_club_name,\n        t.from_club_name,\n        p.date_of_birth,\n        p.position,\n        (SELECT pv.market_value_in_eur\n         FROM player_valuations pv\n         WHERE pv.player_id = t.player_id\n           AND pv.date <= t.transfer_date\n         ORDER BY pv.date DESC LIMIT 1\n        ) AS value_at_transfer,\n        (SELECT pv2.market_value_in_eur\n         FROM player_valuations pv2\n         WHERE pv2.player_id = t.player_id\n           AND pv2.date > DATE(t.transfer_date, '+10 months')\n         ORDER BY pv2.date ASC LIMIT 1\n        ) AS value_after_1yr\n    FROM transfers t\n    JOIN players p ON t.player_id = p.player_id\n    WHERE t.transfer_fee > 5000000\n      AND t.transfer_date >= '2015-01-01'\n      AND t.transfer_date <= '2024-01-01'\n''', conn)\n\n# Calculate ROI and value change\ndf_transfers['roi_pct'] = (\n    (df_transfers['value_after_1yr'] - df_transfers['transfer_fee'])\n    / df_transfers['transfer_fee'] * 100\n).round(1)\n\ndf_transfers['value_change_pct'] = (\n    (df_transfers['value_after_1yr'] - df_transfers['value_at_transfer'])\n    / df_transfers['value_at_transfer'] * 100\n).round(1)\n\n# Age at transfer (handle NaN birth dates)\nbirth = pd.to_datetime(df_transfers['date_of_birth'], errors='coerce')\ntransfer = pd.to_datetime(df_transfers['transfer_date'], errors='coerce')\ndf_transfers['age_at_transfer'] = ((transfer - birth).dt.days / 365.25).round(0)\n\n# Drop rows without 1-year valuation\ndf_valid = df_transfers.dropna(subset=['value_after_1yr', 'value_at_transfer'])\nprint(f\"Transfers with fee >5M: {len(df_transfers)}, with 1yr valuation: {len(df_valid)}\")\n\n# --- ROI Distribution ---\ndef roi_category(roi):\n    if roi > 50: return 'Excellent (>50%)'\n    if roi >= 0: return 'Positive (0-50%)'\n    if roi >= -50: return 'Moderate Loss'\n    return 'Significant Loss'\n\ndf_valid = df_valid.copy()\ndf_valid['roi_cat'] = df_valid['roi_pct'].apply(roi_category)\nroi_dist = df_valid.groupby('roi_cat').agg(\n    count=('roi_pct', 'size'),\n    avg_roi=('roi_pct', 'mean')\n).round(1).reset_index().rename(columns={'roi_cat': 'category'})\n\n# Sort in logical order\ncat_order = ['Excellent (>50%)', 'Positive (0-50%)', 'Moderate Loss', 'Significant Loss']\nroi_dist['_order'] = roi_dist['category'].map({c: i for i, c in enumerate(cat_order)})\nroi_dist = roi_dist.sort_values('_order').drop(columns='_order')\n\n# --- Net Spend (last 5 years) ---\ndf_paid = pd.read_sql('''\n    SELECT to_club_name AS club, SUM(transfer_fee) AS paid\n    FROM transfers\n    WHERE transfer_fee > 0 AND transfer_date >= DATE('now', '-5 years')\n    GROUP BY to_club_name\n''', conn)\n\ndf_received = pd.read_sql('''\n    SELECT from_club_name AS club, SUM(transfer_fee) AS received\n    FROM transfers\n    WHERE transfer_fee > 0 AND transfer_date >= DATE('now', '-5 years')\n    GROUP BY from_club_name\n''', conn)\n\ndf_net = df_paid.merge(df_received, on='club', how='outer').fillna(0)\ndf_net['net_spend'] = (df_net['received'] - df_net['paid']).astype(int)\n\n# Top 6 spenders + Top 6 sellers\ntop_spenders = df_net.nsmallest(6, 'net_spend')\ntop_sellers = df_net.nlargest(6, 'net_spend')\nnet_spend = pd.concat([top_spenders, top_sellers.iloc[::-1]]).drop_duplicates(subset='club')\nnet_spend = net_spend[['club', 'net_spend']].sort_values('net_spend')\n\n# --- Scatter: Top 200 transfers ---\nscatter = df_valid.nlargest(200, 'transfer_fee')[['transfer_fee', 'value_change_pct', 'age_at_transfer', 'player_name']].copy()\nscatter.columns = ['fee', 'value_change', 'age', 'name']\nscatter = scatter.dropna()\nscatter['age'] = scatter['age'].astype(int)\n\n# --- Assemble and save ---\nanalytics = {\n    'roi_distribution': roi_dist.to_dict('records'),\n    'net_spend': net_spend.to_dict('records'),\n    'scatter': scatter.to_dict('records'),\n    'total_analyzed': int(len(df_valid)),\n}\nsave('transfer_analytics.json', analytics)\ndisplay(roi_dist)\nprint(f\"\\nNet spend entries: {len(net_spend)}, Scatter points: {len(scatter)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "zqp9jhjylhf",
   "source": "## 7. club_financials.json\n\nTop 20 clubs by squad value (Big 5 leagues). Reuses the SQL from `sql/07_club_financials.sql` and adds age group breakdowns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "5nm2q4rzu7m",
   "source": "# Read the existing SQL file\nsql_path = Path('..') / 'sql' / '07_club_financials.sql'\nclub_sql = sql_path.read_text(encoding='utf-8')\n\ndf_clubs = pd.read_sql(club_sql, conn)\n\n# --- Fix 1: League names (competitions table has slugs like \"premier-league\") ---\n# Map via domestic_competition_id from clubs table\nleague_for_club = pd.read_sql('''\n    SELECT name AS club_name, domestic_competition_id AS league_id\n    FROM clubs\n    WHERE domestic_competition_id IN ('GB1','ES1','IT1','L1','FR1')\n''', conn)\nclub_league_map = dict(zip(league_for_club['club_name'], league_for_club['league_id'].map(LEAGUE_NAMES)))\n\n# --- Fix 2: Shorten club names ---\n# Remove common suffixes from full legal names\ndef shorten_club_name(name):\n    replacements = [\n        ' Football Club', ' Club de Fútbol', ' Fútbol Club',\n        ' S.p.A.', ' S.A.D.', ' S.S.C.', ' S.p.a.',\n        ' Associazione Calcica', ' Associazione Calcio',\n        ' Associazione Sportiva',\n    ]\n    short = name\n    for r in replacements:\n        short = short.replace(r, '')\n    # Specific well-known mappings for readability\n    name_map = {\n        'Real Madrid': 'Real Madrid',\n        'Manchester City': 'Man City',\n        'Arsenal': 'Arsenal',\n        'Paris Saint-Germain': 'PSG',\n        'Chelsea': 'Chelsea',\n        'Liverpool': 'Liverpool',\n        'Futbol Club Barcelona': 'Barcelona',\n        'FC Bayern München': 'Bayern Munich',\n        'Tottenham Hotspur': 'Tottenham',\n        'Manchester United': 'Man United',\n        'Newcastle United': 'Newcastle',\n        'Football Club Internazionale Milano': 'Inter Milan',\n        'Milan': 'AC Milan',\n        'Aston Villa': 'Aston Villa',\n        'Nottingham Forest': 'Nott. Forest',\n        'Club Atlético de Madrid': 'Atletico Madrid',\n        'Juventus': 'Juventus',\n        'Crystal Palace': 'Crystal Palace',\n        'Roma': 'AS Roma',\n        'Brighton and Hove Albion': 'Brighton',\n    }\n    return name_map.get(short.strip(), short.strip())\n\n# Age group breakdown per club\ndf_age = pd.read_sql('''\n    SELECT\n        cl.name AS club_name,\n        CASE\n            WHEN CAST((julianday('now') - julianday(p.date_of_birth)) / 365.25 AS INTEGER) < 21 THEN 'U21'\n            WHEN CAST((julianday('now') - julianday(p.date_of_birth)) / 365.25 AS INTEGER) < 25 THEN '21-24'\n            WHEN CAST((julianday('now') - julianday(p.date_of_birth)) / 365.25 AS INTEGER) < 29 THEN '25-28'\n            WHEN CAST((julianday('now') - julianday(p.date_of_birth)) / 365.25 AS INTEGER) < 33 THEN '29-32'\n            ELSE '33+'\n        END AS age_group,\n        COUNT(*) AS count,\n        SUM(p.market_value_in_eur) AS value\n    FROM players p\n    JOIN clubs cl ON p.current_club_id = cl.club_id\n    WHERE cl.domestic_competition_id IN ('GB1','ES1','IT1','L1','FR1')\n      AND p.date_of_birth IS NOT NULL\n      AND p.market_value_in_eur > 0\n    GROUP BY cl.name, age_group\n    ORDER BY cl.name, age_group\n''', conn)\n\n# --- Fix 3: Sort age groups logically ---\nAGE_ORDER = ['U21', '21-24', '25-28', '29-32', '33+']\n\nage_by_club = {}\nfor club_name, group in df_age.groupby('club_name'):\n    records = group[['age_group', 'count', 'value']].rename(columns={'age_group': 'group'}).to_dict('records')\n    records.sort(key=lambda r: AGE_ORDER.index(r['group']) if r['group'] in AGE_ORDER else 99)\n    age_by_club[club_name] = records\n\n# --- Fix 4: ROI -- cap at reasonable range, use net_transfer_balance for context ---\n# Original formula: (squad_value - invested) / invested * 100\n# Problem: clubs with low investment but high academy value get absurd ROI\n# Solution: cap ROI and add net_balance as additional context\n\ndf_top = df_clubs.head(20)\nclubs_out = []\nfor _, row in df_top.iterrows():\n    raw_roi = float(row['investment_roi_pct'] or 0)\n    # Cap ROI at +/- 200% to avoid misleading extremes\n    capped_roi = max(-200.0, min(200.0, raw_roi))\n\n    clubs_out.append({\n        'name': shorten_club_name(row['club_name']),\n        'league': club_league_map.get(row['club_name'], row['league_name']),\n        'squad_value': int(row['total_squad_value'] or 0),\n        'avg_age': float(row['average_age'] or 0),\n        'star_dependency': float(row['star_dependency_pct'] or 0),\n        'invested_5yr': int(row['invested_5yr'] or 0),\n        'roi': round(capped_roi, 1),\n        'positions': {\n            'Attack': int(row['attack_value'] or 0),\n            'Midfield': int(row['midfield_value'] or 0),\n            'Defender': int(row['defender_value'] or 0),\n            'Goalkeeper': int(row['goalkeeper_value'] or 0),\n        },\n        'age_groups': age_by_club.get(row['club_name'], []),\n    })\n\nsave('club_financials.json', clubs_out)\nprint(f\"\\nTop 5 clubs:\")\nfor c in clubs_out[:5]:\n    print(f\"  {c['name']:<20} {c['league']:<18} {c['squad_value']/1e9:.2f}B  ROI={c['roi']}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "moxt9bj8cd",
   "source": "## 8. player_positions.json\n\nPosition treemap (total market value by sub_position) and value distribution histogram.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "9pojdigbzqf",
   "source": "# Treemap: total market value by sub_position\ndf_treemap = pd.read_sql('''\n    SELECT\n        sub_position AS name,\n        position,\n        SUM(market_value_in_eur) AS size\n    FROM players\n    WHERE market_value_in_eur > 0\n      AND sub_position IS NOT NULL\n      AND position IS NOT NULL\n    GROUP BY sub_position, position\n    ORDER BY size DESC\n''', conn)\n\n# Value distribution histogram\ndf_hist = pd.read_sql('''\n    SELECT\n        CASE\n            WHEN market_value_in_eur < 1000000 THEN '<1M'\n            WHEN market_value_in_eur < 5000000 THEN '1-5M'\n            WHEN market_value_in_eur < 10000000 THEN '5-10M'\n            WHEN market_value_in_eur < 20000000 THEN '10-20M'\n            WHEN market_value_in_eur < 50000000 THEN '20-50M'\n            WHEN market_value_in_eur < 100000000 THEN '50-100M'\n            ELSE '>100M'\n        END AS range,\n        COUNT(*) AS count\n    FROM players\n    WHERE market_value_in_eur > 0\n    GROUP BY range\n    ORDER BY MIN(market_value_in_eur)\n''', conn)\n\ntotal_players = int(pd.read_sql('SELECT COUNT(*) as n FROM players WHERE market_value_in_eur > 0', conn).iloc[0, 0])\n\npositions = {\n    'treemap': df_treemap.to_dict('records'),\n    'value_distribution': df_hist.to_dict('records'),\n    'total_players': total_players,\n}\nsave('player_positions.json', positions)\ndisplay(df_treemap.head(5))\nprint(f\"\\nHistogram bins: {len(df_hist)}, Total players: {total_players}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8fi844l0vhm",
   "source": "conn.close()\nprint()\nprint('All 8 JSON files exported. Dashboard now uses real Transfermarkt data.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}