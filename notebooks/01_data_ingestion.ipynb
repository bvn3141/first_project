{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Ingestion\n",
    "\n",
    "This notebook loads the raw CSV files from the Transfermarkt dataset, performs initial cleaning and type conversions, and stores everything in a SQLite database for SQL analysis.\n",
    "\n",
    "**Data Source**: [Football Data from Transfermarkt](https://www.kaggle.com/datasets/davidcariboo/player-scores) (Kaggle)\n",
    "\n",
    "## Pipeline\n",
    "1. Load CSV files into pandas DataFrames\n",
    "2. Inspect data shapes, dtypes, and missing values\n",
    "3. Perform type conversions (dates, numerics)\n",
    "4. Load all tables into SQLite database\n",
    "5. Create indexes for query performance\n",
    "6. Verify data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "DB_PATH = DATA_PROCESSED / \"football.db\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Raw data directory: {DATA_RAW}\")\n",
    "print(f\"Database path: {DB_PATH}\")\n",
    "print(f\"Files in raw directory: {list(DATA_RAW.glob('*.csv'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load CSV Files\n",
    "\n",
    "Load all CSV files from the Kaggle dataset into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define expected CSV files and their names\n",
    "CSV_FILES = {\n",
    "    \"appearances\": \"appearances.csv\",\n",
    "    \"clubs\": \"clubs.csv\",\n",
    "    \"competitions\": \"competitions.csv\",\n",
    "    \"games\": \"games.csv\",\n",
    "    \"players\": \"players.csv\",\n",
    "    \"player_valuations\": \"player_valuations.csv\",\n",
    "    \"transfers\": \"transfers.csv\",\n",
    "    \"club_games\": \"club_games.csv\",\n",
    "    \"game_events\": \"game_events.csv\",\n",
    "}\n",
    "\n",
    "# Load all CSVs\n",
    "dataframes = {}\n",
    "for name, filename in CSV_FILES.items():\n",
    "    filepath = DATA_RAW / filename\n",
    "    if filepath.exists():\n",
    "        df = pd.read_csv(filepath, low_memory=False)\n",
    "        dataframes[name] = df\n",
    "        print(f\"  {name:.<30} {df.shape[0]:>10,} rows x {df.shape[1]:>3} cols\")\n",
    "    else:\n",
    "        print(f\"  {name:.<30} FILE NOT FOUND: {filepath}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(dataframes)} / {len(CSV_FILES)} tables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Inspection\n",
    "\n",
    "Quick overview of each table: columns, data types, missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dataframes.items():\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"TABLE: {name} ({df.shape[0]:,} rows, {df.shape[1]} columns)\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    \n",
    "    # Show columns, types, and null counts\n",
    "    info_df = pd.DataFrame({\n",
    "        \"dtype\": df.dtypes,\n",
    "        \"non_null\": df.count(),\n",
    "        \"null_count\": df.isnull().sum(),\n",
    "        \"null_pct\": (df.isnull().sum() / len(df) * 100).round(1),\n",
    "        \"sample\": df.iloc[0] if len(df) > 0 else None\n",
    "    })\n",
    "    display(info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Type Conversions\n",
    "\n",
    "Parse date columns and ensure numeric columns have correct types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date columns to parse per table\n",
    "DATE_COLUMNS = {\n",
    "    \"games\": [\"date\"],\n",
    "    \"appearances\": [\"date\"],\n",
    "    \"players\": [\"date_of_birth\", \"contract_expiration_date\"],\n",
    "    \"player_valuations\": [\"date\"],\n",
    "    \"transfers\": [\"transfer_date\"],\n",
    "}\n",
    "\n",
    "for table, cols in DATE_COLUMNS.items():\n",
    "    if table in dataframes:\n",
    "        for col in cols:\n",
    "            if col in dataframes[table].columns:\n",
    "                before_nulls = dataframes[table][col].isnull().sum()\n",
    "                dataframes[table][col] = pd.to_datetime(\n",
    "                    dataframes[table][col], errors=\"coerce\"\n",
    "                )\n",
    "                after_nulls = dataframes[table][col].isnull().sum()\n",
    "                new_nulls = after_nulls - before_nulls\n",
    "                print(f\"  {table}.{col}: converted to datetime\"\n",
    "                      f\" ({new_nulls} unparseable values set to NaT)\")\n",
    "\n",
    "print(\"\\nDate conversions complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric columns are properly typed\n",
    "NUMERIC_COLUMNS = {\n",
    "    \"players\": [\"market_value_in_eur\", \"highest_market_value_in_eur\", \"height_in_cm\"],\n",
    "    \"player_valuations\": [\"market_value_in_eur\"],\n",
    "    \"transfers\": [\"transfer_fee\", \"market_value_in_eur\"],\n",
    "    \"clubs\": [\"total_market_value\", \"squad_size\", \"average_age\"],\n",
    "    \"games\": [\"home_club_goals\", \"away_club_goals\", \"attendance\"],\n",
    "    \"appearances\": [\"goals\", \"assists\", \"minutes_played\", \"yellow_cards\", \"red_cards\"],\n",
    "}\n",
    "\n",
    "for table, cols in NUMERIC_COLUMNS.items():\n",
    "    if table in dataframes:\n",
    "        for col in cols:\n",
    "            if col in dataframes[table].columns:\n",
    "                dataframes[table][col] = pd.to_numeric(\n",
    "                    dataframes[table][col], errors=\"coerce\"\n",
    "                )\n",
    "\n",
    "print(\"Numeric type conversions complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load into SQLite Database\n",
    "\n",
    "Store all DataFrames in a SQLite database for SQL analysis in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove existing database to start fresh\n",
    "if DB_PATH.exists():\n",
    "    DB_PATH.unlink()\n",
    "    print(\"Removed existing database.\")\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    df.to_sql(name, conn, if_exists=\"replace\", index=False)\n",
    "    row_count = pd.read_sql_query(f\"SELECT COUNT(*) as cnt FROM [{name}]\", conn)\n",
    "    print(f\"  {name:.<30} {row_count['cnt'].iloc[0]:>10,} rows loaded\")\n",
    "\n",
    "print(f\"\\nDatabase created at: {DB_PATH}\")\n",
    "print(f\"Database size: {DB_PATH.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Indexes\n",
    "\n",
    "Add indexes for frequently queried columns to improve query performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "indexes = [\n",
    "    # Player valuations -- heavily queried\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_pv_player_id ON player_valuations(player_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_pv_date ON player_valuations(date)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_pv_club_comp ON player_valuations(player_club_domestic_competition_id)\",\n",
    "    \n",
    "    # Appearances\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_app_player_id ON appearances(player_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_app_game_id ON appearances(game_id)\",\n",
    "    \n",
    "    # Games\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_games_season ON games(season)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_games_competition ON games(competition_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_games_date ON games(date)\",\n",
    "    \n",
    "    # Transfers\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_transfers_player ON transfers(player_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_transfers_date ON transfers(transfer_date)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_transfers_to_club ON transfers(to_club_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_transfers_from_club ON transfers(from_club_id)\",\n",
    "    \n",
    "    # Players\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_players_club ON players(current_club_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_players_position ON players(position)\",\n",
    "    \n",
    "    # Clubs\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_clubs_competition ON clubs(domestic_competition_id)\",\n",
    "    \n",
    "    # Club games\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_cg_club ON club_games(club_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_cg_game ON club_games(game_id)\",\n",
    "    \n",
    "    # Game events\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_ge_game ON game_events(game_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_ge_player ON game_events(player_id)\",\n",
    "]\n",
    "\n",
    "for idx_sql in indexes:\n",
    "    cursor.execute(idx_sql)\n",
    "    idx_name = idx_sql.split(\"EXISTS \")[1].split(\" ON\")[0]\n",
    "    print(f\"  Created index: {idx_name}\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\n{len(indexes)} indexes created.\")\n",
    "print(f\"Database size after indexing: {DB_PATH.stat().st_size / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verification\n",
    "\n",
    "Run basic integrity checks to ensure data was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "from notebooks.utils.db_helpers import get_connection, run_query, table_info\n",
    "\n",
    "# Show all tables with row counts\n",
    "print(\"Database Tables:\")\n",
    "print(\"=\" * 40)\n",
    "display(table_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks\n",
    "checks = [\n",
    "    (\"Top 5 leagues exist\", \"\"\"\n",
    "        SELECT competition_id, name \n",
    "        FROM competitions \n",
    "        WHERE competition_id IN ('GB1', 'ES1', 'IT1', 'L1', 'FR1')\n",
    "        ORDER BY name\n",
    "    \"\"\"),\n",
    "    (\"Players have market values\", \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_players,\n",
    "            SUM(CASE WHEN market_value_in_eur IS NOT NULL THEN 1 ELSE 0 END) as with_value,\n",
    "            ROUND(AVG(market_value_in_eur), 0) as avg_value\n",
    "        FROM players\n",
    "    \"\"\"),\n",
    "    (\"Transfers have fees\", \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_transfers,\n",
    "            SUM(CASE WHEN transfer_fee > 0 THEN 1 ELSE 0 END) as with_fee,\n",
    "            ROUND(MAX(transfer_fee), 0) as max_fee\n",
    "        FROM transfers\n",
    "    \"\"\"),\n",
    "    (\"Valuation date range\", \"\"\"\n",
    "        SELECT \n",
    "            MIN(date) as earliest,\n",
    "            MAX(date) as latest,\n",
    "            COUNT(DISTINCT player_id) as unique_players\n",
    "        FROM player_valuations\n",
    "    \"\"\"),\n",
    "]\n",
    "\n",
    "for title, query in checks:\n",
    "    print(f\"\\n{title}:\")\n",
    "    display(run_query(query))\n",
    "\n",
    "print(\"\\n All checks passed. Database is ready for analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
